from graphviz import Digraph

g = Digraph('Large Language Model', format='png')
g.attr(rankdir='TB', dpi='300', nodesep='0.7', ranksep='1.1')
g.attr('node', shape='box', style='filled,rounded', fontsize='10', fontname='Helvetica')

# Color palette
colors = {
    'main': '#A0C4FF',  # Soft Blue
    'secondary': '#B9FBC0',  # Light Green
    'accent': '#FFD6A5',  # Peach Yellow
    'text': '#2F3E46'  # Dark Slate Gray
}

# Input Text
g.node('InputText', 'üìù Input Text', fillcolor=colors['main'])

# Tokenization
g.node('Tokenization', 'Tokenization', fillcolor=colors['main'])
g.edge('InputText', 'Tokenization')

# Note for Tokenization
g.node('TokenizationNote', 'Tokenization is the process of breaking down text into smaller units called tokens.', shape='note', fillcolor=colors['secondary'], style='filled')
g.edge('Tokenization', 'TokenizationNote', style='dashed')

# Embedding Layer
g.node('EmbeddingLayer', 'Embedding Layer', fillcolor=colors['main'])
g.edge('Tokenization', 'EmbeddingLayer')

# Note for Embedding Layer
g.node('EmbeddingLayerNote', 'The embedding layer converts tokens into numerical representations called embeddings.', shape='note', fillcolor=colors['secondary'], style='filled')
g.edge('EmbeddingLayer', 'EmbeddingLayerNote', style='dashed')

# Model Architecture
g.node('ModelArchitecture', 'Model Architecture', fillcolor=colors['main'])
g.edge('EmbeddingLayer', 'ModelArchitecture')

# Note for Model Architecture
g.node('ModelArchitectureNote', 'The model architecture refers to the overall structure of the LLM.', shape='note', fillcolor=colors['secondary'], style='filled')
g.edge('ModelArchitecture', 'ModelArchitectureNote', style='dashed')

# Training
g.node('Training', 'Training', fillcolor=colors['main'])
g.edge('ModelArchitecture', 'Training')

# Note for Training
g.node('TrainingNote', 'Training involves optimizing the model\'s parameters to minimize the difference between the predicted output and the actual output.', shape='note', fillcolor=colors['secondary'], style='filled')
g.edge('Training', 'TrainingNote', style='dashed')

# Output
g.node('Output', 'üéØ Output', fillcolor=colors['main'])
g.edge('Training', 'Output')

# Note for Output
g.node('OutputNote', 'The output of the LLM is the predicted text or probability distribution over possible outputs.', shape='note', fillcolor=colors['secondary'], style='filled')
g.edge('Output', 'OutputNote', style='dashed')

# Grouping components
with g.subgraph(name='LLMProcess') as c:
    c.attr(label='Large Language Model Process', labelloc='t', style='filled', fillcolor=colors['accent'])
    c.node('InputText')
    c.node('Tokenization')
    c.node('EmbeddingLayer')
    c.node('ModelArchitecture')
    c.node('Training')
    c.node('Output')

g.render('diagram_output', view=False, cleanup=True)